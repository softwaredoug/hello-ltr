{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow\n",
    "#!pip install tensorflow_hub\n",
    "#!pip install tensorflow_text\n",
    "#!pip install keras\n",
    "\n",
    "\n",
    "import os.path\n",
    "if not os.path.isfile('data/vmware_ir_content.csv'):\n",
    "    !pip install kaggle\n",
    "    !kaggle competitions download -c vmware-zero-shot-information-retrieval\n",
    "    !mkdir -p data/\n",
    "    !unzip -o vmware-zero-shot-information-retrieval.zip\n",
    "    !mv *.csv data/\n",
    "    \n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "use = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-multilingual/3\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "queries = pd.read_csv('data/test.csv')\n",
    "\n",
    "# Created with 'extract_use.py' script\n",
    "queries = pd.read_csv(\"data/test.csv\")\n",
    "corpus = pd.read_pickle('data/vmware_ir_content_parsed.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Title - body pair\n",
    "\n",
    "Intuition:\n",
    "\n",
    "* titles are like queries\n",
    "* title,body label a positive example\n",
    "* the body of the least similar title in an embedding space, is a negative example\n",
    "* Task: use title_vect,body_vect to classify positive from negative examples in a supervised setting\n",
    "*       during inference, use the query instead of a title to score each body as going with on not going with the title/query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_question_in_title(row):\n",
    "    \n",
    "    title = row['titleTag']\n",
    "    if isinstance(title, str) and '?' in title:\n",
    "        true_question = ''\n",
    "        base_title = title.split('|')[0]\n",
    "        if '-' in base_title:\n",
    "            for part in base_title.split('-'):\n",
    "                if '?' in part:\n",
    "                    true_question = part\n",
    "                    break\n",
    "        else:\n",
    "            true_question = base_title\n",
    "        true_question = true_question.strip()\n",
    "        if len(true_question) > 17 and true_question.endswith('?'):\n",
    "            return true_question\n",
    "    return None\n",
    "    \n",
    "corpus['question'] = corpus.apply(identify_question_in_title, axis=1)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_use = corpus[~corpus['question'].isna()]['question'].apply(use)\n",
    "\n",
    "positives = pd.DataFrame()\n",
    "positives['question_use'] = question_use\n",
    "positives['raw_text_use'] = raw_text_use\n",
    "positives['question'] = corpus[~corpus['question'].isna()]['question']\n",
    "positives['raw_text'] = corpus[~corpus['question'].isna()]['raw_text']\n",
    "positives['raw_text_use'] = corpus[~corpus['question'].isna()]['raw_text_use']\n",
    "\n",
    "\n",
    "positives['label'] = 1.0\n",
    "\n",
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_question_from_text(row):\n",
    "    question = row['question']\n",
    "    return row['raw_text'].replace(question, '')\n",
    "\n",
    "positives['raw_text_cleaned'] = positives.apply(remove_question_from_text, axis=1)\n",
    "positives['raw_text_cleaned_use'] = positives['raw_text_cleaned'].apply(use)\n",
    "positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_rounds = 1\n",
    "\n",
    "all_negs = []\n",
    "\n",
    "for _ in range(0, negative_rounds):\n",
    "    negatives = positives.copy()\n",
    "    negatives['raw_text_cleaned_use'] = negatives.sample(frac=1.0)['raw_text_use'].values\n",
    "    negatives['label'] = -1.0\n",
    "    all_negs.append(negatives)\n",
    "    \n",
    "for _ in range(0, negative_rounds):\n",
    "    negatives = positives.copy()\n",
    "    negatives['raw_text_cleaned_use'] = corpus.sample(len(positives))['raw_text_use'].values\n",
    "    negatives['label'] = -1.0\n",
    "    all_negs.append(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.concat(all_negs + [positives])\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm training set behaves as expected\n",
    "\n",
    "- All question embeddings should be identical per question\n",
    "- Raw text embeddings should NOT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sec_ops = training_set[training_set['question'] == 'What is DevSecOps?']\n",
    "assert (dev_sec_ops['question_use'] == dev_sec_ops.iloc[0]['question_use']).all()\n",
    "dev_sec_ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_X(training_set):\n",
    "    raw_text_use = training_set['raw_text_cleaned_use'].numpy()[0]\n",
    "    question_use = training_set['question_use'].numpy()[0]\n",
    "    concated = np.concatenate([question_use, raw_text_use])\n",
    "    return concated\n",
    "    #return np.concatenate(training_set['question_use'].numpy()[0],\n",
    "    #                      training_set['raw_text_use'].numpy()[0])\n",
    "\n",
    "training_set['X'] = training_set.apply(format_X, axis=1)\n",
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confirm embeddings work as expected\n",
    "\n",
    "For a given question/title - our question embeddings should still be first 512, and be identical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_sec_ops = training_set[training_set['question'] == 'What is DevSecOps?']\n",
    "assert (dev_sec_ops['question_use'] == dev_sec_ops.iloc[0]['question_use']).all()\n",
    "\n",
    "def first_of_X(X):\n",
    "    \"\"\"First 512 should be identical\"\"\"\n",
    "    sliced = X[:512]\n",
    "    assert sliced.size == 512, f\"Sliced size is {sliced.size}\"\n",
    "    return sliced\n",
    "\n",
    "should_be_same = dev_sec_ops['X'].apply(first_of_X)\n",
    "first_value = should_be_same.values[0]\n",
    "# should be a cleaner way to do this with pandas, why doesn't the assert above work? Check later\n",
    "for value in should_be_same.values:\n",
    "    assert (first_value == value).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate a model with cross validation\n",
    "\n",
    "Train a binary classifier with Keras using binary classification, use cross validation to find the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=1024, activation='sigmoid'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=8, shuffle=True)\n",
    "estimator = KerasClassifier(build_fn=build_model, epochs=500, batch_size=100, verbose=1)\n",
    "\n",
    "results = cross_val_score(estimator, \n",
    "                          np.stack(training_set['X'].to_numpy()),\n",
    "                          training_set['label'],\n",
    "                          cv=kfold)\n",
    "\n",
    "print(results, results.mean(), results.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(training_set)//10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit( np.stack(training_set['X'].to_numpy()),\n",
    "               training_set['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(np.stack([training_set['X'].iloc[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.predict(np.stack([training_set['X'].iloc[-5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries['query_use'] = queries['Query'].apply(use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_arr = use(\"what is a hypervisor?\").numpy()[0]\n",
    "\n",
    "corpus_for_query = corpus.copy()\n",
    "\n",
    "def format_to_rank(training_set):\n",
    "    raw_text_use = training_set['raw_text_use'].numpy()[0]\n",
    "    concated = np.concatenate([query_arr, raw_text_use])\n",
    "    return concated\n",
    "\n",
    "\n",
    "corpus_for_query['use_with_query'] = corpus_for_query.apply(format_to_rank, axis=1)\n",
    "corpus_for_query['is_match'] = estimator.predict(np.stack(corpus_for_query['use_with_query']))\n",
    "\n",
    "for row in corpus_for_query[(corpus_for_query['is_match'] == 1.0)].to_dict(orient='record')[:10]:\n",
    "    print('----------')\n",
    "    if 'titleTag' in row:\n",
    "        print(row['titleTag'])\n",
    "    else:\n",
    "        print(row['raw_text'][:100])\n",
    "    print()\n",
    "    print()\n",
    "    print()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_submission():\n",
    "    from time import time\n",
    "    timestamp = str(time()).replace('.', '')\n",
    "    fname = f'data/turnbull_submission_{timestamp}.csv'\n",
    "    print(\"Writing To: \", fname)\n",
    "    submission[['QueryId', 'DocumentId']].to_csv(fname, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[['QueryId', 'DocumentId']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_submission()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[corpus['id'].str.contains('https---blogs.vmware.com-cloudprovider-2015-11-simplifying-cloud-spending-with-vmware-subscription-purchase-program.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
